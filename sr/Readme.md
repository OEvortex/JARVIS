# Real-time Voice Recognition System ğŸ¤

[![License: Alpaca 2.0](https://img.shields.io/badge/License-Alpaca%202.0-blue.svg)](https://www.licenses.ai/alpaca-2-0)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=flat&logo=TensorFlow&logoColor=white)](https://tensorflow.org)
[![Made by Abhay](https://img.shields.io/badge/Made%20by-Abhay-purple)](https://github.com/OE-LUCIFER)

> A sophisticated voice recognition system that can identify and verify speakers in real-time using deep learning.

## ğŸŒŸ Key Features

- ğŸ”Š Real-time voice processing
- ğŸ§  Deep Neural Network with 95%+ accuracy
- ğŸ“Š MFCC feature extraction
- âš¡ Low latency (<100ms)
- ğŸ” Type-safe implementation
- ğŸ¯ Easy-to-use training pipeline

## ğŸš€ Quick Start

```bash
# Clone repository
git clone https://github.com/OE-LUCIFER/voice-recognition-system.git

# Install dependencies
pip install -r requirements.txt
cd sr
# Create data directories
mkdir -p data/my_voice data/other_voice
cd..
# Run the system
python main.py
```

## ğŸ“‹ Requirements

- Python 3.8+
- Working microphone
- Dependencies listed in `requirements.txt`

## ğŸ“ How It Works

1. **Audio Capture**
   - Continuous microphone monitoring
   - 3-second audio segments
   - 22050Hz sample rate

2. **Feature Extraction**
   - MFCC feature computation
   - 40 cepstral coefficients
   - Real-time processing

3. **Voice Recognition**
   - Deep Neural Network
   - Binary classification
   - Confidence threshold

## ğŸ§® Model Architecture

```
Input Layer (40) â†’ Dense(512) â†’ Dropout(0.4) â†’
Dense(256) â†’ Dropout(0.3) â†’ Dense(128) â†’ 
Dropout(0.2) â†’ Dense(64) â†’ Dense(1)
```

## ğŸ“‚ Project Structure

```
sr/
â”œâ”€â”€ ğŸ¯ main.py              # Entry point
â”œâ”€â”€ âš™ï¸ config.py            # Settings
â”œâ”€â”€ ğŸ“ types.py            # Type definitions
â”œâ”€â”€ ğŸ¤ feature_extractor.py # MFCC processing
â”œâ”€â”€ ğŸ§  model.py            # Neural network
â””â”€â”€ ğŸ”„ realtime_classifier.py # Live processing
```

## ğŸ› ï¸ Configuration

Edit `config.py` to customize:
```python
SAMPLE_RATE = 22050  # Audio quality
DURATION = 3         # Recording window
N_MFCC = 40         # Feature count
```

## ğŸ“Š Training Data Requirements

1. **Your Voice**
   - 20+ samples in `data/my_voice/`
   - 3 seconds each
   - Clear speech

2. **Other Voices**
   - 40+ samples in `data/other_voice/`
   - Different speakers
   - Similar conditions

## ğŸ“ Citation

If you use this project, please cite:

```bibtex
@software{vortex2024voice,
  author = {Abhay (Vortex)},
  title = {Real-time Voice Recognition System},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/OE-LUCIFER/voice-recognition-system}
}
```

## ğŸ¤ Contributing

1. Fork it
2. Create feature branch (`git checkout -b feature/awesome`)
3. Commit changes (`git commit -am 'Add awesome feature'`)
4. Push (`git push origin feature/awesome`)
5. Open Pull Request

## ğŸ“„ License

This project is licensed under the Alpaca 2.0 License.

## â­ Support

If this project helped you, please consider giving it a â­!

## ğŸ™ Acknowledgments

- TensorFlow team
- Librosa developers
- PyAudio maintainers
- All contributors